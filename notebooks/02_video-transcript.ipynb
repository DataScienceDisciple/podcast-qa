{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import googleapiclient.discovery\n",
    "import re\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get transcripts from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_any(string, phrases):\n",
    "    return any(phrase in string for phrase in phrases)\n",
    "\n",
    "def get_transcript_segments(video_id, video_title):\n",
    "  # Set up the API key and service object.\n",
    "  api_service_name = \"youtube\"\n",
    "  api_version = \"v3\"\n",
    "  youtube = googleapiclient.discovery.build(\n",
    "      api_service_name, api_version, developerKey=YT_API_KEY)\n",
    "\n",
    "  # Call the YouTube API to retrieve the metadata of the video.\n",
    "  request = youtube.videos().list(\n",
    "      part=\"id,snippet,contentDetails,statistics\",\n",
    "      id=video_id\n",
    "  )\n",
    "  response = request.execute()\n",
    "\n",
    "  # Retrieve the segments from the video description.\n",
    "  segments = []\n",
    "  titles = []\n",
    "  if 'description' in response['items'][0]['snippet']:\n",
    "    description = response['items'][0]['snippet']['description']\n",
    "    lines = description.split(\"\\n\")\n",
    "    for line in lines:\n",
    "      timestamp_match = re.search(r\"\\d+:\\d+:\\d+|\\d+:\\d+\", line)\n",
    "      if timestamp_match:\n",
    "        segments.append(timestamp_match.group())\n",
    "        titles.append(line[timestamp_match.end():][1:])\n",
    "\n",
    "  # Retrieve the transcript of the video.\n",
    "  transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "  sponsor_segment_phrases = [\"AG1\", \"Athletic Greens\", \"Inside Tracker\", \"Sponsors\", \"Sponsor\", \"ROKA\", \"Levels\", \"Magic Spoon\", \"Blinkist\"]\n",
    "\n",
    "  # Iterate through the items in the transcript and match them with the relevant segments.\n",
    "  matched_segments = {}\n",
    "  for i in range(len(segments) - 1):\n",
    "    start_segment = segments[i]\n",
    "    end_segment = segments[i+1]\n",
    "    if not contains_any(titles[i], sponsor_segment_phrases):\n",
    "      segment_title = titles[i][:100]\n",
    "      key_title = f\"Episode {video_title}, Segment {segment_title} ({start_segment} {end_segment})\".replace(\"/\", \" \").replace(\":\", \"-\")\n",
    "      matched_segments[key_title] = []\n",
    "      for item in transcript:\n",
    "        start_time = item['start']\n",
    "        end_time = item['start'] + item['duration']\n",
    "        if start_time >= to_seconds(start_segment) and end_time <= to_seconds(end_segment):\n",
    "          matched_segments[key_title].append(item['text'])\n",
    "  for title, text in matched_segments.items():\n",
    "    matched_segments[title] = ' '.join(text).replace('\\n',' ')\n",
    "  return matched_segments\n",
    "\n",
    "def to_seconds(timestamp):\n",
    "  parts = list(map(int, timestamp.split(\":\")))\n",
    "  if len(parts) == 2:\n",
    "    return parts[0] * 60 + parts[1]\n",
    "  elif len(parts) == 3:\n",
    "    return parts[0] * 3600 + parts[1] * 60 + parts[2]\n",
    "  \n",
    "def save_segments_to_txt(matched_segments):\n",
    "  for title, text in matched_segments.items():\n",
    "    print(title)\n",
    "    with open(os.path.join('data', 'transcripts', f'{title}.txt'), \"w\") as f:\n",
    "      f.write(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_data = pd.read_csv(os.path.join('data', 'video_metadata.csv'))\n",
    "# Replace the API key below with a valid API key.\n",
    "YT_API_KEY = os.environ['YT_API_KEY']\n",
    "\n",
    "# Replace the video ID below with a valid video ID.\n",
    "VIDEO_ID = video_data.loc[0, 'videoId']\n",
    "VIDEO_TITLE = video_data.loc[0, 'title']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all podcast segments to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_videos = []\n",
    "for key, item in video_data.iterrows():\n",
    "    video_id = item['videoId']\n",
    "    video_title = item['title']\n",
    "    print(video_title)\n",
    "    try:\n",
    "        matched_segments = get_transcript_segments(video_id, video_title)\n",
    "    except:\n",
    "        print(f\"Video failed: {video_title}\")\n",
    "        failed_videos.append(video_title)\n",
    "    save_segments_to_txt(matched_segments)\n",
    "print(matched_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_videos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename inconsistent filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    # Check which format the timestamp is in and convert it to \"00-00-00\"\n",
    "    if '-' not in t:\n",
    "        return f\"00-00-{int(t):02}\"\n",
    "    elif t.count('-') == 1:\n",
    "        m, s = t.split('-')\n",
    "        return f\"00-{int(m):02}-{int(s):02}\"\n",
    "    else:\n",
    "        h, m, s = t.split('-')\n",
    "        return f\"{int(h):02}-{int(m):02}-{int(s):02}\"\n",
    "\n",
    "# Specify the directory you want to start from\n",
    "rootDir = os.path.join('data', 'summaries') # Change this to your directory path\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "    for fname in fileList:\n",
    "        # Search for filenames containing timestamps in the last set of parentheses with timestamp-like format\n",
    "        match = re.search(r'\\(([0-9\\-]*?)\\s([0-9\\-]*?)\\)\\.txt$', fname)\n",
    "        if match:\n",
    "            old_timestamp1, old_timestamp2 = match.groups()\n",
    "            #print(old_timestamp1, old_timestamp2)\n",
    "            new_timestamp1 = format_time(old_timestamp1)\n",
    "            new_timestamp2 = format_time(old_timestamp2)\n",
    "            # Construct the new filename\n",
    "            new_fname = re.sub(r'\\(([0-9\\-]*?)\\s([0-9\\-]*?)\\)\\.txt$', f'({new_timestamp1} {new_timestamp2}).txt', fname)\n",
    "            if fname != new_fname:\n",
    "                print(fname)\n",
    "                print(new_fname)\n",
    "                # Rename the file\n",
    "                os.rename(os.path.join(dirName, fname), os.path.join(dirName, new_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
